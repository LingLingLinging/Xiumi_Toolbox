"""
æç®€ç½‘é¡µè®¿é—®å·¥å…·
è·å–æ•´ä¸ªé¡µé¢æºç ä¿å­˜åˆ°åˆ—è¡¨ï¼Œæ”¯æŒCookie
"""

import requests
import json
import os
import time
from datetime import datetime


def get_xiumi_cookies():
    """
    è·å–ç§€ç±³Cookieçš„ä¾¿æ·æ–¹å¼
    """
    print("è¯·é€‰æ‹©Cookieè¾“å…¥æ–¹å¼:")
    print("1. ä½¿ç”¨å·²çŸ¥çš„ç§€ç±³Cookie")
    print("2. æ‰‹åŠ¨è¾“å…¥å®Œæ•´Cookieå­—ç¬¦ä¸²")
    print("3. ä¸ä½¿ç”¨Cookie")
    
    choice = input("è¯·é€‰æ‹© (1/2/3): ").strip()
    
    if choice == '1':
        # ä½¿ç”¨æ‚¨æä¾›çš„æœ€æ–°Cookieä¿¡æ¯
        xiumi_cookies = {
            '_ga': 'GA1.1.138683111.1741960991',
            '_ga_082SS7M4WJ': 'GS1.1.1742122869.2.1.1742127827.0.0.0',
            '_ga_MPF5T5D71D': 'GS2.1.s1753021340$o30$g1$t1753021341$j59$l0$h0',
            'sid': 's%3A9z_-F6Q4Z2hubkFfEXsC5JRHsqtL02Qc.DgmCQxcq5gEV3oIkcKp0xs3Rx0viEgGR4deSuNZf11Y'
        }
        print("âœ“ ä½¿ç”¨æœ€æ–°çš„ç§€ç±³Cookie")
        return xiumi_cookies
    
    elif choice == '2':
        cookie_str = input("è¯·ç²˜è´´Cookieå­—ç¬¦ä¸²: ").strip()
        if cookie_str:
            return cookie_str
        return None
    
    else:
        return None


def get_full_page_lines_with_cookies(url: str, cookies=None, wait_seconds=5) -> tuple:
    """
    è·å–æ•´ä¸ªé¡µé¢çš„æ‰€æœ‰è¡Œï¼Œæ”¯æŒCookieå’Œç­‰å¾…æ—¶é—´
    
    Args:
        url: ç½‘é¡µURL
        cookies: Cookieå­—å…¸æˆ–å­—ç¬¦ä¸²
        wait_seconds: ç­‰å¾…ç§’æ•°ï¼Œè®©é¡µé¢åŠ è½½å®Œæˆ
        
    Returns:
        åŒ…å«æ‰€æœ‰HTMLè¡Œçš„åˆ—è¡¨å’Œå®Œæ•´HTMLå†…å®¹
    """
    try:
        # åˆ›å»ºsession
        session = requests.Session()
        
        # è®¾ç½®headers
        session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36 Edge/120.0.0.0',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'zh-CN,zh;q=0.9,en;q=0.8',
            'Accept-Encoding': 'gzip, deflate, br',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
            'Sec-Fetch-Dest': 'document',
            'Sec-Fetch-Mode': 'navigate',
            'Sec-Fetch-Site': 'none',
            'Referer': 'https://xiumi.us/',
        })
        
        # è®¾ç½®Cookie
        if cookies:
            if isinstance(cookies, dict):
                for name, value in cookies.items():
                    session.cookies.set(name, value, domain='xiumi.us')
            elif isinstance(cookies, str):
                # è§£æCookieå­—ç¬¦ä¸²
                for cookie in cookies.split(';'):
                    if '=' in cookie:
                        name, value = cookie.strip().split('=', 1)
                        session.cookies.set(name, value, domain='xiumi.us')
        
        print(f"æ­£åœ¨è¯·æ±‚: {url}")
        if cookies:
            print("âœ“ ä½¿ç”¨æœ€æ–°Cookieè®¿é—®")
            print(f"âœ“ Cookieæ•°é‡: {len(session.cookies)}")
        
        # å‘èµ·è¯·æ±‚
        response = session.get(url, timeout=30)
        
        # ç­‰å¾…é¡µé¢åŠ è½½ï¼ˆå¯¹äºåŠ¨æ€å†…å®¹ï¼‰
        if wait_seconds > 0:
            print(f"ç­‰å¾… {wait_seconds} ç§’è®©é¡µé¢åŠ¨æ€å†…å®¹åŠ è½½å®Œæˆ...")
            time.sleep(wait_seconds)
            
            # å¯èƒ½éœ€è¦å†æ¬¡è¯·æ±‚è·å–åŠ¨æ€åŠ è½½çš„å†…å®¹
            response = session.get(url, timeout=30)
        
        if response.status_code == 200:
            print(f"âœ“ è®¿é—®æˆåŠŸï¼ŒçŠ¶æ€ç : {response.status_code}")
            print(f"âœ“ å“åº”å¤§å°: {len(response.text)} å­—ç¬¦")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰ç™»å½•çŠ¶æ€
            if 'login' in response.text.lower() or 'ç™»å½•' in response.text:
                print("âš ï¸  é¡µé¢å¯èƒ½åŒ…å«ç™»å½•ç›¸å…³å†…å®¹")
            if 'user' in response.text.lower() or 'ç”¨æˆ·' in response.text:
                print("âœ“ é¡µé¢å¯èƒ½åŒ…å«ç”¨æˆ·ç›¸å…³å†…å®¹")
                
            # è·å–æ•´ä¸ªé¡µé¢ï¼ŒæŒ‰è¡Œåˆ†å‰²æˆåˆ—è¡¨
            all_lines = response.text.splitlines()
            return all_lines, response.text  # è¿”å›è¡Œåˆ—è¡¨å’Œå®Œæ•´HTML
        else:
            return [f"é”™è¯¯ï¼šçŠ¶æ€ç  {response.status_code}"], None
            
    except Exception as e:
        return [f"é”™è¯¯ï¼š{e}"], None


def save_html_file(html_content: str, url: str, save_dir: str = "saved_pages"):
    """
    ä¿å­˜HTMLå†…å®¹åˆ°æ–‡ä»¶ï¼ˆåŸæ ·ä¿å­˜ï¼‰
    
    Args:
        html_content: HTMLå†…å®¹
        url: åŸå§‹URL
        save_dir: ä¿å­˜ç›®å½•
        
    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    try:
        # åˆ›å»ºä¿å­˜ç›®å½•
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_url = url.replace('://', '_').replace('/', '_').replace('?', '_').replace('#', '_')[:30]
        filename = f"xiumi_page_{timestamp}_{safe_url}.html"
        filepath = os.path.join(save_dir, filename)
        
        # åŸæ ·ä¿å­˜HTMLæ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ“ HTMLæ–‡ä»¶å·²ä¿å­˜: {filepath}")
        print(f"âœ“ æ–‡ä»¶å¤§å°: {len(html_content)} å­—ç¬¦")
        return filepath
        
    except Exception as e:
        print(f"ä¿å­˜HTMLæ–‡ä»¶å¤±è´¥: {e}")
        return None


def save_search_results(search_results: list, search_term: str, save_dir: str = "saved_pages"):
    """
    ä¿å­˜æœç´¢ç»“æœåˆ°HTMLæ–‡ä»¶
    
    Args:
        search_results: æœç´¢ç»“æœåˆ—è¡¨ [(è¡Œå·, å†…å®¹), ...]
        search_term: æœç´¢å…³é”®è¯
        save_dir: ä¿å­˜ç›®å½•
    """
    try:
        if not search_results:
            return
            
        # åˆ›å»ºä¿å­˜ç›®å½•
        if not os.path.exists(save_dir):
            os.makedirs(save_dir)
        
        # ç”Ÿæˆæ–‡ä»¶å
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        safe_term = search_term.replace(' ', '_').replace('/', '_')[:20]
        filename = f"search_results_{safe_term}_{timestamp}.html"
        filepath = os.path.join(save_dir, filename)
        
        # ç”ŸæˆHTMLå†…å®¹
        html_content = f"""
<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>æœç´¢ç»“æœ - {search_term}</title>
    <style>
        body {{ font-family: Arial, sans-serif; margin: 20px; background: #f5f5f5; }}
        .header {{ background: #007acc; color: white; padding: 20px; margin-bottom: 20px; border-radius: 5px; }}
        .result {{ margin: 10px 0; padding: 15px; border-left: 4px solid #007acc; background: white; border-radius: 3px; box-shadow: 0 1px 3px rgba(0,0,0,0.1); }}
        .line-num {{ color: #666; font-weight: bold; font-size: 12px; }}
        .highlight {{ background: #ffeb3b; padding: 2px 4px; border-radius: 2px; }}
        .content {{ margin-top: 8px; font-family: monospace; word-break: break-all; }}
    </style>
</head>
<body>
    <div class="header">
        <h2>ğŸ” æœç´¢ç»“æœ</h2>
        <p><strong>æœç´¢å…³é”®è¯:</strong> {search_term}</p>
        <p><strong>æ‰¾åˆ°ç»“æœ:</strong> {len(search_results)} ä¸ª</p>
        <p><strong>ç”Ÿæˆæ—¶é—´:</strong> {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}</p>
    </div>
"""
        
        for line_num, content in search_results:
            # é«˜äº®æ˜¾ç¤ºæœç´¢å…³é”®è¯ï¼ˆå¤§å°å†™ä¸æ•æ„Ÿï¼‰
            import re
            highlighted_content = re.sub(
                f'({re.escape(search_term)})', 
                r'<span class="highlight">\1</span>', 
                content, 
                flags=re.IGNORECASE
            )
            html_content += f"""
    <div class="result">
        <div class="line-num">ç¬¬ {line_num} è¡Œ</div>
        <div class="content">{highlighted_content}</div>
    </div>
"""
        
        html_content += """
</body>
</html>
"""
        
        # ä¿å­˜æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(html_content)
        
        print(f"âœ“ æœç´¢ç»“æœå·²ä¿å­˜: {filepath}")
        return filepath
        
    except Exception as e:
        print(f"ä¿å­˜æœç´¢ç»“æœå¤±è´¥: {e}")
        return None


def search_in_page(page_lines: list, search_term: str):
    """åœ¨é¡µé¢ä¸­æœç´¢å…³é”®è¯"""
    matches = []
    for line_num, line in enumerate(page_lines, 1):
        if search_term.lower() in line.lower():
            matches.append((line_num, line.strip()))
    
    if matches:
        print(f"\nğŸ¯ æ‰¾åˆ° {len(matches)} ä¸ªåŒ¹é…ç»“æœ:")
        for line_num, content in matches[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
            # æˆªæ–­è¿‡é•¿çš„å†…å®¹
            display_content = content[:200] + "..." if len(content) > 200 else content
            print(f"ç¬¬{line_num}è¡Œ: {display_content}")
        if len(matches) > 10:
            print(f"... è¿˜æœ‰ {len(matches) - 10} ä¸ªç»“æœ")
            
        # è¯¢é—®æ˜¯å¦ä¿å­˜æœç´¢ç»“æœ
        save_choice = input("\næ˜¯å¦ä¿å­˜æœç´¢ç»“æœåˆ°HTMLæ–‡ä»¶? (y/n): ").strip().lower()
        if save_choice == 'y':
            save_search_results(matches, search_term)
            
    else:
        print(f"âŒ æ²¡æœ‰æ‰¾åˆ°åŒ…å«'{search_term}'çš„è¡Œ")
    
    return matches


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸŒŸ ç§€ç±³ç½‘é¡µè®¿é—®å·¥å…· (å·²æ›´æ–°Cookie)")
    print("=" * 60)
    
    # è·å–Cookie
    cookies = get_xiumi_cookies()
    
    # è¾“å…¥URL
    url = input("\nè¯·è¾“å…¥ç§€ç±³ç½‘é¡µURL: ").strip()
    if not url:
        return
    
    # è®¾ç½®ç­‰å¾…æ—¶é—´
    wait_time = input("\nè¯·è¾“å…¥ç­‰å¾…æ—¶é—´(ç§’ï¼Œé»˜è®¤5ç§’): ").strip()
    try:
        wait_seconds = int(wait_time) if wait_time else 5
    except ValueError:
        wait_seconds = 5
        
    print(f"\nğŸš€ æ­£åœ¨è·å–æ•´ä¸ªé¡µé¢: {url}")
    print(f"â±ï¸  å°†ç­‰å¾… {wait_seconds} ç§’è®©é¡µé¢å®Œå…¨åŠ è½½")
    
    # è·å–æ•´ä¸ªé¡µé¢ä¿å­˜åˆ° page_lines åˆ—è¡¨ä¸­
    result = get_full_page_lines_with_cookies(url, cookies, wait_seconds)
    if len(result) == 2:
        page_lines, full_html = result
    else:
        page_lines, full_html = result, None
    
    if page_lines and page_lines[0].startswith("é”™è¯¯ï¼š"):
        print(f"âŒ {page_lines[0]}")
        return
    
    print(f"âœ… é¡µé¢è·å–å®Œæˆï¼Œå…± {len(page_lines)} è¡Œ")
    
    # è¯¢é—®æ˜¯å¦ä¿å­˜å®Œæ•´HTML
    if full_html:
        save_choice = input("\nğŸ’¾ æ˜¯å¦ä¿å­˜å®Œæ•´é¡µé¢åˆ°HTMLæ–‡ä»¶? (y/n): ").strip().lower()
        if save_choice == 'y':
            saved_file = save_html_file(full_html, url)
            if saved_file:
                print(f"ğŸ“‚ å¯ä»¥ç”¨æµè§ˆå™¨æ‰“å¼€æŸ¥çœ‹: {os.path.abspath(saved_file)}")
    
    # æ˜¾ç¤ºå‰3è¡Œå†…å®¹é¢„è§ˆ
    print("\nğŸ“„ å‰3è¡Œå†…å®¹é¢„è§ˆ:")
    for i, line in enumerate(page_lines[:3], 1):
        display_line = line[:100] + "..." if len(line) > 100 else line
        print(f"ç¬¬{i}è¡Œ: {display_line}")
    
    # å¾ªç¯æœç´¢
    print("\nğŸ” å¼€å§‹æœç´¢æ¨¡å¼ (è¾“å…¥å…³é”®è¯è¿›è¡Œæœç´¢)")
    while True:
        search_term = input("\nè¯·è¾“å…¥æœç´¢å…³é”®è¯ (è¾“å…¥'quit'é€€å‡º): ").strip()
        if search_term.lower() == 'quit':
            print("ğŸ‘‹ ç¨‹åºç»“æŸ")
            break
        if search_term:
            search_in_page(page_lines, search_term)


if __name__ == "__main__":
    main()
